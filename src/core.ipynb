{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are going to look at making the GloVE based version of Node2Vec\n",
    "\n",
    "This is the GloVE as node2vec is to word2vec.\n",
    "\n",
    "Papers:\n",
    "\n",
    " - [GloVE](http://www.aclweb.org/anthology/D14-1162)\n",
    " - [node2vec](https://cs.stanford.edu/people/jure/pubs/node2vec-kdd16.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "pkg\"activate ..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we want to avoid taking random walks\n",
    "\n",
    "Node2Vec takes random walks, to get sequences of word(nodes), which it feeds to word2vec.\n",
    "\n",
    "Instread we want to get a matrix that corresponds to the co-occurrencee matrix in GloVE.\n",
    "Which has elements that are weighted counts of how often words(nodes) occur in the same window.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ is the adjancency matrix.\n",
    "Nodes directly connected to neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a co-occurrence matrix $X$,\n",
    "which has entries given by the count of how often each node occurred in the context of another node.\n",
    "Where context is determined by window size.\n",
    "\n",
    "Graph theory tells us for nodes, $i$ and $j$\n",
    " - $A_{ij}$ is there a connection between node $i$ and node $j$\n",
    " - $(A^2)_{ij}$ number of walks of length 2 from node $i$ to node $j$\n",
    " - $(A^n)_{ij}$ number of walks of length n from node $i$ to node $j$\n",
    " \n",
    " \n",
    "GLoVE uses decreasing weighting such that words $d$ apart contribute $\\frac{1}{d}$ to the coocurance count  (GloVE paper section 4.2).\n",
    "\n",
    "\n",
    "Thus for window size $N$,\n",
    "\n",
    "$$\n",
    "X = \\sum_{n=1}^{n=N}   \\frac{A^n}{n}\n",
    "$$\n",
    "\n",
    "\n",
    "This (I believe) extends intutitively and without change to:\n",
    " - using a **weight** matrix instread of an **adjancency** matrix.\n",
    " - Or to using a directed graph, via **asymetrical** adjancency matrix\n",
    " - Or both.\n",
    "Normalization may be required.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cooccurance_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cooccurance_matrix(W, window_size)\n",
    "    X = Float32.(W)\n",
    "    Wp = W\n",
    "    \n",
    "    for n in 2 : window_size\n",
    "        Wp *= W\n",
    "        X .+= Wp./n\n",
    "    end\n",
    "    X\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside of this method is that it is fairly expensive.\n",
    "Matrix multiplication of a matrix with average $k$ nonzero elements\n",
    "is (slightly better in theory, but roughly) $O(k^3)$.  \n",
    "Thus for window size $N$,\n",
    "that the calculation of the cooccurance matrix is\n",
    "$O(nk^3)$  \n",
    "Not also that sparsity doesn't help as much as we would like,\n",
    "and each successive matrix multiplication is less sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec biased walks:\n",
    " \n",
    " Quoting:  [node2vec paper](https://cs.stanford.edu/people/jure/pubs/node2vec-kdd16.pdf)\n",
    " section 3.2.2 Search bias\n",
    " \n",
    "The simplest way to bias our random walks would be to sample the next node based on the static edge weights $w_{vx}$ i.e, $\\pi_{vx} = w_{vx}$. (In case of unweighted graphs $w_{vx}=1$.) However, this does not allow us to account for the network structure and guide our search procedure to explore different types of network neighborhoods. \n",
    "Additionally, unlike BFS and DFS which are extreme sampling paradigms suited for structural equivalence and homophily respectively, our random walks should accommodate for the fact that these notions of equivalence are not competing or exclusive, and real-world networks commonly exhibit a mixture of both. \n",
    "\n",
    "We define a 2$^{\\textrm{nd}}$ order random walk with two parameters $p$ and $q$ which guide the walk: Consider a random walk that just traversed edge $(t,v)$ and now resides at node $v$ . The walk now needs to decide on the next step so it evaluates the transition probabilities $\\pi_{vx}$ on edges $(v,x)$ leading from $v$. We set the unnormalized transition probability to $\\pi_{vx} = \\alpha_{pq}(t,x)\\cdot w_{vx}$, where \n",
    "\n",
    "$$\n",
    "\t\\alpha_{pq}(t,x) = \n",
    "\t\\begin{cases}\n",
    "\t\\frac{1}{p}  & \\text{if } d_{tx} = 0\\\\\n",
    "\t1 & \\text{if } d_{tx} = 1\\\\\n",
    "\t\\frac{1}{q} & \\text{if } d_{tx} = 2\n",
    "\t\\end{cases}\n",
    "$$\n",
    "\n",
    "and $d_{tx}$ denotes the shortest path distance between nodes $t$ and $x$. Note that $d_{tx}$ must be one of $\\{0,1,2\\}$, and hence, the two parameters are necessary and sufficient to guide the walk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "α (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function π_vx(W, t,v,x; p=1, q=1)\n",
    "    w_vx = @inbounds W[v,x]\n",
    "    w_vx == 0 && return 0\n",
    "    π_vx = α(W, t, x; p=p, q=q) * w_vx\n",
    "end\n",
    "\n",
    "function α(W, t, x; p=1, q=1)\n",
    "    if t==x #d_tx=0\n",
    "        1/p\n",
    "    elseif @inbounds W[t,x] > 0 #d_tx=1\n",
    "        1\n",
    "    else #d_tx=2 as go t->v,v->x\n",
    "        1/q\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the collocation matrix\n",
    "\n",
    "This is an overload of the `cooccurance_matrix`\n",
    "to take the extra arguments for `p` and `q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cooccurance_matrix (generic function with 3 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cooccurance_matrix(graph_weights, window_size, p=1, q=1)\n",
    "    W = sparse(graph_weights)\n",
    "    X = copy(W)\n",
    "    \n",
    "    πW1=copy(W) # First step\n",
    "    for d in 2:window_size\n",
    "        πW2=spzeros(size(W)...) # whipe it\n",
    "        for (t, v, val) in zip(findnz(πW1)...)\n",
    "            xs = SparseArrays.nonzeroinds(@inbounds W[v,:])\n",
    "            for x in xs\n",
    "                @inbounds πW2[v, x] += π_vx(W, t,v,x; p=p, q=q)\n",
    "            end\n",
    "        end\n",
    "        πW1 *= πW2\n",
    "        X .+= πW1/=d # GloVE proximity weighting\n",
    "    end\n",
    "    X\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets solve GLoVE\n",
    "\n",
    "Fine matrixes C and V such that\n",
    "$$\n",
    "loss = f(X)(CV - \\log X)^2\n",
    "$$\n",
    "is minimized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use \n",
    "\n",
    " - Optim as a global optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the problem.  \n",
    "We will be storing $C$ and $V$ in the same matrix as that is how Optim likes ot handle memory. We call that combo `CV`.\n",
    "\n",
    "We also need to define the weighting function $f$ (we use the GLoVE defn here, I don't think it is optimal though.)\n",
    "\n",
    "And the Loss, which we express as function of X that returns a function of `CV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_CV(CV)\n",
    "    C = @view(CV[:, 1:end÷2])'\n",
    "    V = @view(CV[:, end÷2+1:end])\n",
    "    C,V\n",
    "end\n",
    "\n",
    "function f(x)\n",
    "    xmax = 100\n",
    "    α = 2/3\n",
    "    \n",
    "    x < xmax ? (x/xmax)^α : 1.0\n",
    "end\n",
    "\n",
    "loss(X)=function (CV)\n",
    "    C,V = split_CV(CV)\n",
    "    sum(f.(X) * (C*V .- log.(X)).^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to build the optimiser,  \n",
    "this will take in the Collocation matrix `X` and the number of dimensions to use.  \n",
    "This  can be tweaked a fair bit;\n",
    "\n",
    "kwparams:\n",
    "\n",
    " - `time_limit` max time to run for in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nodeGLoVE (generic function with 2 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nodeGLoVE(X, num_dims=16; time_limit = 5*60)\n",
    "    num_dims = 16\n",
    "    CV = randn(num_dims, 2size(X,1)) # Twice the size as we need to split it off\n",
    "    res = optimize(loss(X), CV, LBFGS(), \n",
    "        Optim.Options(show_trace=true,\n",
    "            #iterations = 200\n",
    "            time_limit = time_limit\n",
    "            ))\n",
    "    C,V = split_CV(res.minimizer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
